# ğŸš— Used Car Price Prediction with Machine Learning

This project aims to predict the prices of used cars based on various vehicle attributes. The analysis involves data cleaning, feature engineering, exploratory data analysis, and applying regression models such as Linear Regression, Random Forest, and Gradient Boosting.

---

## ğŸ¯ Project Objective

To build and evaluate predictive models that can estimate the selling price of a used car given features like year, present price, kilometers driven, fuel type, seller type, transmission, and ownership status.

---

## ğŸ“ Dataset Overview

- **Source:** Kaggle â€“ Used Car Dataset
- **Features:**
  - `Year` â€“ Year of manufacturing
  - `Present_Price` â€“ Current ex-showroom price of the car
  - `Kms_Driven` â€“ Distance driven in kilometers
  - `Fuel_Type` â€“ Petrol, Diesel, or CNG
  - `Seller_Type` â€“ Individual or Dealer
  - `Transmission` â€“ Manual or Automatic
  - `Owner` â€“ Number of previous owners
  - `Selling_Price` â€“ Target variable

---

## ğŸ” Exploratory Data Analysis (EDA)

- Distribution plots for selling price and other continuous variables
- Count plots for categorical features
- Pair plots and correlation heatmaps to visualize relationships
- Skewness analysis and outlier detection

---

## âš™ï¸ Feature Engineering

- Conversion of `Year` to `Car_Age`
- One-hot encoding for categorical features like `Fuel_Type`, `Seller_Type`, and `Transmission`
- Removal of redundant or highly collinear features

---

## ğŸ§  Machine Learning Models Used

- **Linear Regression**
- **Random Forest Regressor**
- **Gradient Boosting Regressor**

Models were trained and evaluated based on **RÂ² Score**, **MAE**, and **RMSE**.

---

## ğŸ“Š Key Visualizations

- Feature importance from tree-based models
- Actual vs Predicted price scatter plot
- Residual error distribution plots
- Bar charts comparing model performances

---

## ğŸ§ª Results Summary

| Model                  | RÂ² Score | MAE     | RMSE    |
|------------------------|----------|---------|---------|
| Linear Regression      | 0.86     | ~1.25   | ~2.10   |
| Random Forest Regressor| 0.94     | ~0.50   | ~1.00   |
| Gradient Boosting      | 0.96     | ~0.40   | ~0.85   |

> Gradient Boosting Regressor performed best on validation data with the highest RÂ² and lowest error metrics.

---

## ğŸ› ï¸ Tools & Technologies

- Python
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn

---






